{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFECV\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('../db/out/wta_s.csv')\n",
    "\n",
    "df_2023 = df[df['date'].str.contains(\n",
    "    '2023', na=False) | df['date'].str.contains('2022', na=False)]\n",
    "\n",
    "df.drop(df_2023.index, inplace=True)\n",
    "\n",
    "non_numeric_columns = df.select_dtypes(['object']).columns\n",
    "\n",
    "df_numeric_only = df.drop(non_numeric_columns, axis=1)\n",
    "\n",
    "df = df_numeric_only\n",
    "\n",
    "df = df.drop(['match_id'], axis=1)\n",
    "\n",
    "df = df.fillna(df.median())\n",
    "\n",
    "df = df.fillna(df.median())\n",
    "\n",
    "\n",
    "Y = pd.DataFrame(df['y'])\n",
    "df = df.drop(['y'], axis=1)\n",
    "X = df\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.1, random_state=45, stratify=Y)\n",
    "\n",
    "non_numeric_columns = df_2023.select_dtypes(['object']).columns\n",
    "\n",
    "df_numeric_only = df_2023.drop(non_numeric_columns, axis=1)\n",
    "\n",
    "df_2023 = df_numeric_only\n",
    "\n",
    "df_2023 = df_2023.drop(['match_id'], axis=1)\n",
    "\n",
    "df_2023 = df_2023.fillna(df_2023.median())\n",
    "\n",
    "y_2023 = pd.DataFrame(df_2023['y'])\n",
    "x_2023 = df_2023.drop(['y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trening\n",
      "{'0': {'precision': 0.6767270288397049, 'recall': 0.7046089385474861, 'f1-score': 0.6903865891207663, 'support': 1432.0}, '1': {'precision': 0.6969914040114613, 'recall': 0.6687285223367697, 'f1-score': 0.682567520168362, 'support': 1455.0}, 'accuracy': 0.686525805334257, 'macro avg': {'precision': 0.6868592164255831, 'recall': 0.686668730442128, 'f1-score': 0.6864770546445642, 'support': 2887.0}, 'weighted avg': {'precision': 0.6869399370055884, 'recall': 0.686525805334257, 'f1-score': 0.6864459083705937, 'support': 2887.0}}\n",
      "Walidacja\n",
      "{'0': {'precision': 0.6473719228210246, 'recall': 0.6794692737430168, 'f1-score': 0.6630323679727428, 'support': 1432.0}, '1': {'precision': 0.6605029585798816, 'recall': 0.6275474349964862, 'f1-score': 0.6436036036036036, 'support': 1423.0}, 'accuracy': 0.6535901926444834, 'macro avg': {'precision': 0.6539374407004531, 'recall': 0.6535083543697515, 'f1-score': 0.6533179857881732, 'support': 2855.0}, 'weighted avg': {'precision': 0.6539167437964549, 'recall': 0.6535901926444834, 'f1-score': 0.6533486090595081, 'support': 2855.0}}\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Basic parameters\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "model = HistGradientBoostingClassifier(random_state=45)\n",
    "\n",
    "result = model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "basic_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "print(\"Trening\")\n",
    "print(basic_report)\n",
    "basic_pre = basic_report['weighted avg']['precision']\n",
    "\n",
    "\n",
    "pred_val = model.predict(x_2023)\n",
    "basic_report = classification_report(y_2023, pred_val, output_dict=True)\n",
    "print(\"Walidacja\")\n",
    "print(basic_report)\n",
    "basic_pre_val = basic_report['weighted avg']['precision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best Score: 0.6734019730397548\n",
      "Best Hyperparameters: {'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Hyperparameter Tuning\n",
    "model = HistGradientBoostingClassifier(random_state=45)\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': list(np.arange(0.1, 1.1, 0.1)),\n",
    "    'n_estimators': list(range(100, 180, 10)),\n",
    "    'criterion': ['friedman_mse', 'squared_error'],\n",
    "    'loss': ['log_loss', 'exponential'],\n",
    "}\n",
    "\n",
    "\n",
    "search = GridSearchCV(model, param_grid,\n",
    "                      cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "result = search.fit(X_train, y_train)\n",
    "\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features : 21\n",
      "                             Rank\n",
      "games_played                    1\n",
      "completeness                    1\n",
      "serve_points_won                1\n",
      "points_on_return                1\n",
      "aceDf                           1\n",
      "double_fault_probability        1\n",
      "second_won_serve                1\n",
      "first_won_serve                 1\n",
      "bp_factor                       1\n",
      "surface_wins                    1\n",
      "win_percentage                  1\n",
      "total_serve_points              1\n",
      "ace_probability                 1\n",
      "glicko                          1\n",
      "rank_points                     1\n",
      "rank                            1\n",
      "aceDf_vs                        1\n",
      "double_fault_probability_vs     1\n",
      "ace_probability_vs              1\n",
      "first_won_serve_vs              1\n",
      "bp_factor_vs                    1\n",
      "elo                             2\n",
      "win_percentage_vs               3\n",
      "ht                              4\n",
      "second_won_serve_vs             5\n",
      "Trening\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This GradientBoostingClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\OneDrivePW\\OneDrive - Politechnika Warszawska\\Documents\\PracaIn≈ºynierska\\Software\\master\\ml_gradientboost.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrivePW/OneDrive%20-%20Politechnika%20Warszawska/Documents/PracaIn%C5%BCynierska/Software/master/ml_gradientboost.ipynb#W3sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m opti_pre \u001b[39m=\u001b[39m opti_report[\u001b[39m'\u001b[39m\u001b[39mweighted avg\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mprecision\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrivePW/OneDrive%20-%20Politechnika%20Warszawska/Documents/PracaIn%C5%BCynierska/Software/master/ml_gradientboost.ipynb#W3sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m opti_f1 \u001b[39m=\u001b[39m opti_report[\u001b[39m'\u001b[39m\u001b[39mweighted avg\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mf1-score\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/OneDrivePW/OneDrive%20-%20Politechnika%20Warszawska/Documents/PracaIn%C5%BCynierska/Software/master/ml_gradientboost.ipynb#W3sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m opti_auc \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39mroc_auc_score(y_test, model\u001b[39m.\u001b[39;49mpredict_proba(X_test)[::, \u001b[39m1\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrivePW/OneDrive%20-%20Politechnika%20Warszawska/Documents/PracaIn%C5%BCynierska/Software/master/ml_gradientboost.ipynb#W3sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m pred_val \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(x_2023)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrivePW/OneDrive%20-%20Politechnika%20Warszawska/Documents/PracaIn%C5%BCynierska/Software/master/ml_gradientboost.ipynb#W3sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m opti_val_report \u001b[39m=\u001b[39m classification_report(y_2023, pred_val, output_dict\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\march\\anaconda3\\envs\\Tenis2\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1333\u001b[0m, in \u001b[0;36mGradientBoostingClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_proba\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m   1313\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Predict class probabilities for X.\u001b[39;00m\n\u001b[0;32m   1314\u001b[0m \n\u001b[0;32m   1315\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1331\u001b[0m \u001b[39m        If the ``loss`` does not support probabilities.\u001b[39;00m\n\u001b[0;32m   1332\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1333\u001b[0m     raw_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecision_function(X)\n\u001b[0;32m   1334\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1335\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_loss\u001b[39m.\u001b[39m_raw_prediction_to_proba(raw_predictions)\n",
      "File \u001b[1;32mc:\\Users\\march\\anaconda3\\envs\\Tenis2\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1242\u001b[0m, in \u001b[0;36mGradientBoostingClassifier.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1221\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute the decision function of ``X``.\u001b[39;00m\n\u001b[0;32m   1222\u001b[0m \n\u001b[0;32m   1223\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1237\u001b[0m \u001b[39m    array of shape (n_samples,).\u001b[39;00m\n\u001b[0;32m   1238\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1239\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[0;32m   1240\u001b[0m     X, dtype\u001b[39m=\u001b[39mDTYPE, order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m, accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1241\u001b[0m )\n\u001b[1;32m-> 1242\u001b[0m raw_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raw_predict(X)\n\u001b[0;32m   1243\u001b[0m \u001b[39mif\u001b[39;00m raw_predictions\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1244\u001b[0m     \u001b[39mreturn\u001b[39;00m raw_predictions\u001b[39m.\u001b[39mravel()\n",
      "File \u001b[1;32mc:\\Users\\march\\anaconda3\\envs\\Tenis2\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:678\u001b[0m, in \u001b[0;36mBaseGradientBoosting._raw_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_raw_predict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    677\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the sum of the trees raw predictions (+ init estimator).\"\"\"\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     raw_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raw_predict_init(X)\n\u001b[0;32m    679\u001b[0m     predict_stages(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_, X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlearning_rate, raw_predictions)\n\u001b[0;32m    680\u001b[0m     \u001b[39mreturn\u001b[39;00m raw_predictions\n",
      "File \u001b[1;32mc:\\Users\\march\\anaconda3\\envs\\Tenis2\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:664\u001b[0m, in \u001b[0;36mBaseGradientBoosting._raw_predict_init\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    662\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_raw_predict_init\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    663\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check input and compute raw predictions of the init estimator.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_initialized()\n\u001b[0;32m    665\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_validate_X_predict(X, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    666\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit_ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzero\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\march\\anaconda3\\envs\\Tenis2\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:367\u001b[0m, in \u001b[0;36mBaseGradientBoosting._check_initialized\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_initialized\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    366\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that the estimator is initialized, raising an error if not.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 367\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\march\\anaconda3\\envs\\Tenis2\\lib\\site-packages\\sklearn\\utils\\validation.py:1462\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1459\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not an estimator instance.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (estimator))\n\u001b[0;32m   1461\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1462\u001b[0m     \u001b[39mraise\u001b[39;00m NotFittedError(msg \u001b[39m%\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mtype\u001b[39m(estimator)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This GradientBoostingClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# Gradient Boosting with RFECV\n",
    "\n",
    "model = GradientBoostingClassifier(\n",
    "    loss='log_loss', learning_rate=0.1, n_estimators=110, criterion='friedman_mse')\n",
    "\n",
    "cv = StratifiedKFold(3)\n",
    "\n",
    "rfecv = RFECV(model, cv=cv, scoring='accuracy', step=1)\n",
    "\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfecv.predict(X_test)\n",
    "\n",
    "print('Optimal number of features : %d' % rfecv.n_features_)\n",
    "\n",
    "ranks = pd.DataFrame(\n",
    "    rfecv.ranking_, index=X.columns, columns=['Rank'])\n",
    "\n",
    "print(ranks.sort_values(by='Rank', ascending=True))\n",
    "\n",
    "selected_features = ranks[ranks['Rank'] == 1].index.values.tolist()\n",
    "\n",
    "opti_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "print(\"Trening\")\n",
    "opti_pre = opti_report['weighted avg']['precision']\n",
    "opti_f1 = opti_report['weighted avg']['f1-score']\n",
    "opti_auc = metrics.roc_auc_score(y_test, model.predict_proba(X_test)[::, 1])\n",
    "\n",
    "\n",
    "pred_val = model.predict(x_2023)\n",
    "opti_val_report = classification_report(y_2023, pred_val, output_dict=True)\n",
    "print(\"Walidacja\")\n",
    "print(opti_val_report)\n",
    "opti_pre_val = opti_val_report['weighted avg']['precision']\n",
    "opti_f1_val = opti_val_report['weighted avg']['f1-score']\n",
    "opti_auc_val = metrics.roc_auc_score(\n",
    "    y_2023, model.predict_proba(x_2023)[::, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trening\n",
      "Walidacja\n",
      "{'0': {'precision': 0.6510067114093959, 'recall': 0.6773743016759777, 'f1-score': 0.6639288158795347, 'support': 1432.0}, '1': {'precision': 0.6615384615384615, 'recall': 0.634574841883345, 'f1-score': 0.6477761836441894, 'support': 1423.0}, 'accuracy': 0.6560420315236427, 'macro avg': {'precision': 0.6562725864739287, 'recall': 0.6559745717796613, 'f1-score': 0.655852499761862, 'support': 2855.0}, 'weighted avg': {'precision': 0.6562559865175082, 'recall': 0.6560420315236427, 'f1-score': 0.6558779592522505, 'support': 2855.0}}\n"
     ]
    }
   ],
   "source": [
    "# rfecv.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = rfecv.predict(X_test)\n",
    "\n",
    "\n",
    "opti_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "print(\"Trening\")\n",
    "opti_pre = opti_report['weighted avg']['precision']\n",
    "opti_f1 = opti_report['weighted avg']['f1-score']\n",
    "opti_auc = metrics.roc_auc_score(y_test, rfecv.predict_proba(X_test)[::, 1])\n",
    "\n",
    "\n",
    "pred_val = rfecv.predict(x_2023)\n",
    "opti_val_report = classification_report(y_2023, pred_val, output_dict=True)\n",
    "print(\"Walidacja\")\n",
    "print(opti_val_report)\n",
    "opti_pre_val = opti_val_report['weighted avg']['precision']\n",
    "opti_f1_val = opti_val_report['weighted avg']['f1-score']\n",
    "opti_auc_val = metrics.roc_auc_score(\n",
    "    y_2023, rfecv.predict_proba(x_2023)[::, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "filename = 'results.json'\n",
    "\n",
    "final_results = {\n",
    "    \"prediction_basic\": basic_pre,\n",
    "    \"v_prcision_basic\": basic_pre_val,\n",
    "    \"prediction_optimized\": opti_pre,\n",
    "    \"v_prcision_optimized\": opti_pre_val,\n",
    "    \"f1_score_opt\": opti_f1,\n",
    "    \"f1_score_opt_val\": opti_f1_val,\n",
    "    \"auc_opt\": float(opti_auc),\n",
    "    \"auc_opt_val\": float(opti_auc_val),\n",
    "    \"selected_features\": selected_features,\n",
    "}\n",
    "\n",
    "\n",
    "with open(filename, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "data['Wzmocnienie gradientowe'] = (final_results)\n",
    "\n",
    "\n",
    "with open('results.json', 'w') as file:\n",
    "    json.dump(data, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
