{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFECV\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, time, timedelta\n",
    "\n",
    "df = pd.read_csv('../db/out/wta_s.csv')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df_2023 = df[df['date'].str.contains(\n",
    "    '2023', na=False) | df['date'].str.contains('2022', na=False)]\n",
    "\n",
    "df.drop(df_2023.index, inplace=True)\n",
    "\n",
    "non_numeric_columns = df_2023.select_dtypes(['object']).columns\n",
    "\n",
    "df_numeric_only = df_2023.drop(non_numeric_columns, axis=1)\n",
    "\n",
    "df_2023 = df_numeric_only\n",
    "\n",
    "df_2023 = df_2023.drop(['match_id'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "df_2023 = df_2023.fillna(df_2023.median())\n",
    "\n",
    "y_2023 = pd.DataFrame(df_2023['y'])\n",
    "x_2023 = df_2023.drop(['y'], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_2023 = scaler.fit_transform(x_2023)\n",
    "\n",
    "non_numeric_columns = df.select_dtypes(['object']).columns\n",
    "\n",
    "df_numeric_only = df.drop(non_numeric_columns, axis=1)\n",
    "\n",
    "df = df_numeric_only\n",
    "\n",
    "df = df.drop(['match_id'], axis=1)\n",
    "\n",
    "df = df.fillna(df.median())\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Y = pd.DataFrame(df['y'])\n",
    "df = df.drop(['y'], axis=1)\n",
    "X = df\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.1, random_state=45, stratify=Y)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier(random_state=45, max_iter=200)\n",
    "\n",
    "\n",
    "result = model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "basic_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "print(\"Trening\")\n",
    "print(basic_report)\n",
    "basic_pre = basic_report['weighted avg']['precision']\n",
    "\n",
    "\n",
    "\n",
    "pred_val = model.predict(x_2023)\n",
    "basic_report = classification_report(y_2023, pred_val, output_dict=True)\n",
    "print(\"Walidacja\")\n",
    "print(basic_report)\n",
    "basic_pre_val = basic_report['weighted avg']['precision']\n",
    "\n",
    "auc_basic = metrics.roc_auc_score(y_test, model.predict_proba(X_test)[::, 1])\n",
    "print(\"AUC: \", auc_basic)\n",
    "\n",
    "auc_val = metrics.roc_auc_score(y_2023, model.predict_proba(x_2023)[::, 1])\n",
    "print(\"AUC: \", auc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras import Input\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import History\n",
    "# import keras_tuner as kt\n",
    "from pathlib import Path\n",
    "from time import strftime\n",
    "# from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "# def get_run_logdir(root_logdir=\"my_run_logs\"):\n",
    "#     return Path(root_logdir) / strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "\n",
    "# tensorbord_cb = keras.callbacks.TensorBoard(\n",
    "#     get_run_logdir(), profile_batch=(100, 200))\n",
    "\n",
    "\n",
    "# history = History()\n",
    "\n",
    "# # use keras API\n",
    "# tf.random.set_seed(49)\n",
    "\n",
    "\n",
    "# def build_model(hp):\n",
    "#     n_hidden = hp.Int('n_hidden', min_value=1, max_value=4, step=1)\n",
    "#     n_neurons = hp.Int('n_neurons', min_value=10, max_value=65, step=5)\n",
    "#     learning_rate = hp.Float(\"learning_rate\", min_value=0.0001, max_value=0.01,\n",
    "#                              sampling=\"log\")\n",
    "#     kernel_regularizer = hp.Choice('kernel_regularizer', ['l1', 'l2'])\n",
    "#     kernel_initializer = hp.Choice(\n",
    "#         'kernel_initializer', ['he_normal', 'glorot_normal', 'lecun_normal'])\n",
    "#     activation = hp.Choice('activation', ['relu', 'selu', 'sigmoid', 'tanh'])\n",
    "#     optimizer = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop'])\n",
    "#     if optimizer == 'adam':\n",
    "#         optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "#     elif optimizer == 'sgd':\n",
    "#         optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "#     else:\n",
    "#         optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "#     model = keras.Sequential()\n",
    "#     model.add(Input(shape=X_train.shape[1]))\n",
    "#     for _ in range(n_hidden):\n",
    "#         model.add(Dense(n_neurons, activation=activation,\n",
    "#                   kernel_regularizer=kernel_regularizer, kernel_initializer=kernel_initializer))\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "#     model.compile(optimizer=optimizer,\n",
    "#                   loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#     return model\n",
    "\n",
    "\n",
    "# model = tf.keras.Sequential()\n",
    "\n",
    "\n",
    "# random_search_tuner = kt.BayesianOptimization(\n",
    "#     build_model,\n",
    "#     objective='val_accuracy',\n",
    "#     max_trials=25,\n",
    "#     executions_per_trial=3,\n",
    "#     directory='my_dir',\n",
    "#     project_name='wta_ann_bayesian_optimization',\n",
    "#     overwrite=True)\n",
    "\n",
    "# random_search_tuner.search(X_train, y_train, epochs=15,\n",
    "#                            validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "# top3_models = random_search_tuner.get_best_models(num_models=3)\n",
    "# best_model = top3_models[0]\n",
    "\n",
    "# best_trial = random_search_tuner.oracle.get_best_trials(num_trials=1)[0]\n",
    "# best_trial.summary()\n",
    "\n",
    "\n",
    "# best_trial.metrics.get_last_value(\"val_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=X_train.shape[1]))\n",
    "    model.add(Dense(96, activation='selu',\n",
    "          kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l1_l2(0.1, 0.2)))\n",
    "#     model.add(Dropout(0.4))\n",
    "#     model.add(Dense(96, activation='relu',\n",
    "#           kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(0.05)))\n",
    "#     model.add(Dropout(0.6))\n",
    "#     model.add(Dense(96, activation='relu',\n",
    "#           kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(0.05)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    optim = keras.optimizers.SGD(learning_rate=0.001969)\n",
    "    model.compile(optimizer=optim,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model()\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=256, validation_data=(x_2023, y_2023))\n",
    "test_loss, test_acc = model.evaluate(x_2023, y_2023)\n",
    "# # model = KerasClassifier(model=create_model, epochs=100, batch_size=32, validation_)\n",
    "# model.fit(X_train, y_train)\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# opti_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "# print(\"Trening\")\n",
    "# print(opti_report)\n",
    "# opti_pre = opti_report['weighted avg']['precision']\n",
    "# opti_f1 = opti_report['weighted avg']['f1-score']\n",
    "# opti_auc = metrics.roc_auc_score(y_test, model.predict(X_test))\n",
    "\n",
    "\n",
    "\n",
    "# pred_val = model.predict(x_2023)\n",
    "# opti_val_report = classification_report(y_2023, pred_val, output_dict=True)\n",
    "# print(\"Walidacja\")\n",
    "# print(opti_val_report)\n",
    "# opti_pre_val = opti_val_report['weighted avg']['precision']\n",
    "# opti_f1_val = opti_val_report['weighted avg']['f1-score']\n",
    "# opti_auc_val = metrics.roc_auc_score(y_2023, model.predict(x_2023))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# filename = 'results.json'\n",
    "\n",
    "# final_results = {\n",
    "#     \"prediction_basic\": basic_pre,\n",
    "#     \"v_prcision_basic\": basic_pre_val,\n",
    "#     \"prediction_optimized\": opti_pre,\n",
    "#     \"v_prcision_optimized\": opti_pre_val,\n",
    "#     \"f1_score_opt\": opti_f1,\n",
    "#     \"f1_score_opt_val\": opti_f1_val,\n",
    "#     \"auc_opt\": float(opti_auc),\n",
    "#     \"auc_opt_val\": float(opti_auc_val),\n",
    "# }\n",
    "\n",
    "\n",
    "# with open(filename, 'r') as file:\n",
    "#     data = json.load(file)\n",
    "\n",
    "\n",
    "# data['Sztuczna sieć neuronowa'] = (final_results)\n",
    "\n",
    "\n",
    "# with open('results.json', 'w') as file:\n",
    "#     json.dump(data, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
