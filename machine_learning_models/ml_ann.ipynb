{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28870 entries, 0 to 28869\n",
      "Data columns (total 25 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   win_percentage_vs            28870 non-null  float64\n",
      " 1   bp_factor_vs                 28870 non-null  float64\n",
      " 2   first_won_serve_vs           28870 non-null  float64\n",
      " 3   second_won_serve_vs          28870 non-null  float64\n",
      " 4   ace_probability_vs           28870 non-null  float64\n",
      " 5   double_fault_probability_vs  28870 non-null  float64\n",
      " 6   aceDf_vs                     28870 non-null  float64\n",
      " 7   rank                         28870 non-null  float64\n",
      " 8   rank_points                  28870 non-null  float64\n",
      " 9   elo                          28870 non-null  float64\n",
      " 10  glicko                       28870 non-null  float64\n",
      " 11  ht                           28870 non-null  float64\n",
      " 12  games_played                 28870 non-null  int64  \n",
      " 13  win_percentage               28870 non-null  float64\n",
      " 14  surface_wins                 28870 non-null  float64\n",
      " 15  bp_factor                    28870 non-null  float64\n",
      " 16  first_won_serve              28870 non-null  float64\n",
      " 17  second_won_serve             28870 non-null  float64\n",
      " 18  double_fault_probability     28870 non-null  float64\n",
      " 19  aceDf                        28870 non-null  float64\n",
      " 20  points_on_return             28870 non-null  float64\n",
      " 21  serve_points_won             28870 non-null  float64\n",
      " 22  completeness                 28870 non-null  float64\n",
      " 23  total_serve_points           28870 non-null  float64\n",
      " 24  ace_probability              28870 non-null  float64\n",
      "dtypes: float64(24), int64(1)\n",
      "memory usage: 5.5 MB\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFECV\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, time, timedelta\n",
    "\n",
    "df = pd.read_csv('../db/out/wta_s.csv')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df_2023 = df[df['date'].str.contains(\n",
    "    '2023', na=False) | df['date'].str.contains('2022', na=False)]\n",
    "\n",
    "df.drop(df_2023.index, inplace=True)\n",
    "\n",
    "non_numeric_columns = df_2023.select_dtypes(['object']).columns\n",
    "\n",
    "df_numeric_only = df_2023.drop(non_numeric_columns, axis=1)\n",
    "\n",
    "df_2023 = df_numeric_only\n",
    "\n",
    "df_2023 = df_2023.drop(['match_id'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "df_2023 = df_2023.fillna(df_2023.median())\n",
    "\n",
    "y_2023 = pd.DataFrame(df_2023['y'])\n",
    "x_2023 = df_2023.drop(['y'], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_2023 = scaler.fit_transform(x_2023)\n",
    "\n",
    "non_numeric_columns = df.select_dtypes(['object']).columns\n",
    "\n",
    "df_numeric_only = df.drop(non_numeric_columns, axis=1)\n",
    "\n",
    "df = df_numeric_only\n",
    "\n",
    "df = df.drop(['match_id'], axis=1)\n",
    "\n",
    "df = df.fillna(df.median())\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Y = pd.DataFrame(df['y'])\n",
    "df = df.drop(['y'], axis=1)\n",
    "X = df\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.1, random_state=45, stratify=Y)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\OneDrivePW\\OneDrive - Politechnika Warszawska\\Documents\\PracaInżynierska\\Software\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trening\n",
      "{'0': {'precision': 0.6438082556591211, 'recall': 0.6752793296089385, 'f1-score': 0.6591683708248125, 'support': 1432.0}, '1': {'precision': 0.6642599277978339, 'recall': 0.6323024054982818, 'f1-score': 0.6478873239436619, 'support': 1455.0}, 'accuracy': 0.6536196744024939, 'macro avg': {'precision': 0.6540340917284775, 'recall': 0.6537908675536102, 'f1-score': 0.6535278473842372, 'support': 2887.0}, 'weighted avg': {'precision': 0.6541155583823034, 'recall': 0.6536196744024939, 'f1-score': 0.6534829107582818, 'support': 2887.0}}\n",
      "Walidacja\n",
      "{'0': {'precision': 0.6174089068825911, 'recall': 0.6389664804469274, 'f1-score': 0.6280027453671928, 'support': 1432.0}, '1': {'precision': 0.6234522942461762, 'recall': 0.6015460295151089, 'f1-score': 0.6123032904148784, 'support': 1423.0}, 'accuracy': 0.6203152364273204, 'macro avg': {'precision': 0.6204306005643836, 'recall': 0.6202562549810182, 'f1-score': 0.6201530178910356, 'support': 2855.0}, 'weighted avg': {'precision': 0.6204210750851766, 'recall': 0.6203152364273204, 'f1-score': 0.6201777630914859, 'support': 2855.0}}\n",
      "AUC:  0.7152632993530303\n",
      "AUC:  0.6435031328886569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\OneDrivePW\\OneDrive - Politechnika Warszawska\\Documents\\PracaInżynierska\\Software\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "d:\\OneDrivePW\\OneDrive - Politechnika Warszawska\\Documents\\PracaInżynierska\\Software\\.venv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\OneDrivePW\\OneDrive - Politechnika Warszawska\\Documents\\PracaInżynierska\\Software\\.venv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier(random_state=45, max_iter=200)\n",
    "\n",
    "\n",
    "result = model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "basic_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "print(\"Trening\")\n",
    "print(basic_report)\n",
    "basic_pre = basic_report['weighted avg']['precision']\n",
    "\n",
    "\n",
    "\n",
    "pred_val = model.predict(x_2023)\n",
    "basic_report = classification_report(y_2023, pred_val, output_dict=True)\n",
    "print(\"Walidacja\")\n",
    "print(basic_report)\n",
    "basic_pre_val = basic_report['weighted avg']['precision']\n",
    "\n",
    "auc_basic = metrics.roc_auc_score(y_test, model.predict_proba(X_test)[::, 1])\n",
    "print(\"AUC: \", auc_basic)\n",
    "\n",
    "auc_val = metrics.roc_auc_score(y_2023, model.predict_proba(x_2023)[::, 1])\n",
    "print(\"AUC: \", auc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras import Input\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import History\n",
    "# import keras_tuner as kt\n",
    "from pathlib import Path\n",
    "from time import strftime\n",
    "# from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "# def get_run_logdir(root_logdir=\"my_run_logs\"):\n",
    "#     return Path(root_logdir) / strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "\n",
    "# tensorbord_cb = keras.callbacks.TensorBoard(\n",
    "#     get_run_logdir(), profile_batch=(100, 200))\n",
    "\n",
    "\n",
    "# history = History()\n",
    "\n",
    "# # use keras API\n",
    "# tf.random.set_seed(49)\n",
    "\n",
    "\n",
    "# def build_model(hp):\n",
    "#     n_hidden = hp.Int('n_hidden', min_value=1, max_value=4, step=1)\n",
    "#     n_neurons = hp.Int('n_neurons', min_value=10, max_value=65, step=5)\n",
    "#     learning_rate = hp.Float(\"learning_rate\", min_value=0.0001, max_value=0.01,\n",
    "#                              sampling=\"log\")\n",
    "#     kernel_regularizer = hp.Choice('kernel_regularizer', ['l1', 'l2'])\n",
    "#     kernel_initializer = hp.Choice(\n",
    "#         'kernel_initializer', ['he_normal', 'glorot_normal', 'lecun_normal'])\n",
    "#     activation = hp.Choice('activation', ['relu', 'selu', 'sigmoid', 'tanh'])\n",
    "#     optimizer = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop'])\n",
    "#     if optimizer == 'adam':\n",
    "#         optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "#     elif optimizer == 'sgd':\n",
    "#         optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "#     else:\n",
    "#         optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "#     model = keras.Sequential()\n",
    "#     model.add(Input(shape=X_train.shape[1]))\n",
    "#     for _ in range(n_hidden):\n",
    "#         model.add(Dense(n_neurons, activation=activation,\n",
    "#                   kernel_regularizer=kernel_regularizer, kernel_initializer=kernel_initializer))\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "#     model.compile(optimizer=optimizer,\n",
    "#                   loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#     return model\n",
    "\n",
    "\n",
    "# model = tf.keras.Sequential()\n",
    "\n",
    "\n",
    "# random_search_tuner = kt.BayesianOptimization(\n",
    "#     build_model,\n",
    "#     objective='val_accuracy',\n",
    "#     max_trials=25,\n",
    "#     executions_per_trial=3,\n",
    "#     directory='my_dir',\n",
    "#     project_name='wta_ann_bayesian_optimization',\n",
    "#     overwrite=True)\n",
    "\n",
    "# random_search_tuner.search(X_train, y_train, epochs=15,\n",
    "#                            validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "# top3_models = random_search_tuner.get_best_models(num_models=3)\n",
    "# best_model = top3_models[0]\n",
    "\n",
    "# best_trial = random_search_tuner.oracle.get_best_trials(num_trials=1)[0]\n",
    "# best_trial.summary()\n",
    "\n",
    "\n",
    "# best_trial.metrics.get_last_value(\"val_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/marci/AppData/Local/Programs/Python/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=X_train.shape[1]))\n",
    "    model.add(Dense(96, activation='selu',\n",
    "          kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l1_l2(0.1, 0.2)))\n",
    "#     model.add(Dropout(0.4))\n",
    "#     model.add(Dense(96, activation='relu',\n",
    "#           kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(0.05)))\n",
    "#     model.add(Dropout(0.6))\n",
    "#     model.add(Dense(96, activation='relu',\n",
    "#           kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(0.05)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    optim = keras.optimizers.SGD(learning_rate=0.001969)\n",
    "    model.compile(optimizer=optim,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model()\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=256, validation_data=(x_2023, y_2023))\n",
    "test_loss, test_acc = model.evaluate(x_2023, y_2023)\n",
    "# # model = KerasClassifier(model=create_model, epochs=100, batch_size=32, validation_)\n",
    "# model.fit(X_train, y_train)\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# opti_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "# print(\"Trening\")\n",
    "# print(opti_report)\n",
    "# opti_pre = opti_report['weighted avg']['precision']\n",
    "# opti_f1 = opti_report['weighted avg']['f1-score']\n",
    "# opti_auc = metrics.roc_auc_score(y_test, model.predict(X_test))\n",
    "\n",
    "\n",
    "\n",
    "# pred_val = model.predict(x_2023)\n",
    "# opti_val_report = classification_report(y_2023, pred_val, output_dict=True)\n",
    "# print(\"Walidacja\")\n",
    "# print(opti_val_report)\n",
    "# opti_pre_val = opti_val_report['weighted avg']['precision']\n",
    "# opti_f1_val = opti_val_report['weighted avg']['f1-score']\n",
    "# opti_auc_val = metrics.roc_auc_score(y_2023, model.predict(x_2023))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# filename = 'results.json'\n",
    "\n",
    "# final_results = {\n",
    "#     \"prediction_basic\": basic_pre,\n",
    "#     \"v_prcision_basic\": basic_pre_val,\n",
    "#     \"prediction_optimized\": opti_pre,\n",
    "#     \"v_prcision_optimized\": opti_pre_val,\n",
    "#     \"f1_score_opt\": opti_f1,\n",
    "#     \"f1_score_opt_val\": opti_f1_val,\n",
    "#     \"auc_opt\": float(opti_auc),\n",
    "#     \"auc_opt_val\": float(opti_auc_val),\n",
    "# }\n",
    "\n",
    "\n",
    "# with open(filename, 'r') as file:\n",
    "#     data = json.load(file)\n",
    "\n",
    "\n",
    "# data['Sztuczna sieć neuronowa'] = (final_results)\n",
    "\n",
    "\n",
    "# with open('results.json', 'w') as file:\n",
    "#     json.dump(data, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
