{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFECV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Standard\n",
    "# df = pd.read_csv('../db/out/wta_std.csv')\n",
    "\n",
    "# mean\n",
    "# df = pd.read_csv('../db/out/wta_mean.csv')\n",
    "\n",
    "# pvp\n",
    "# df = pd.read_csv('../db/out/wta_pvp.csv')\n",
    "\n",
    "# mean + pvp\n",
    "# df = pd.read_csv('../db/out/wta_mean_pvp.csv')\n",
    "\n",
    "\n",
    "# df = pd.read_csv('../db/clean_and_no_NaN/match_stats_with_wins.csv')\n",
    "\n",
    "# df = pd.read_csv('../db/clean_and_no_NaN/wta_matches_clean.csv')\n",
    "\n",
    "# df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testp1 = df.filter(regex='_P1_vs$', axis=1)\n",
    "\n",
    "testp2 = df.filter(regex='_P2_vs$', axis=1)\n",
    "\n",
    "\n",
    "feats = list(zip(testp1.columns, testp2.columns))\n",
    "\n",
    "\n",
    "for col_a, col_b in feats:\n",
    "    df[col_a + '_diff'] = df[col_a] - df[col_b]\n",
    "\n",
    "df.drop(testp1.columns, axis=1, inplace=True)\n",
    "\n",
    "df.drop(testp2.columns, axis=1, inplace=True)\n",
    "\n",
    "non_numeric_columns = df.select_dtypes(['object']).columns\n",
    "\n",
    "df = df.drop(non_numeric_columns, axis=1)\n",
    "\n",
    "testp1 = df.filter(regex='_P1$', axis=1)\n",
    "\n",
    "testp2 = df.filter(regex='_P2$', axis=1)\n",
    "\n",
    "feats = list(zip(testp1.columns, testp2.columns))\n",
    "\n",
    "for col_a, col_b in feats:\n",
    "    df[col_a + '_diff'] = df[col_a] - df[col_b]\n",
    "\n",
    "df.drop(testp1.columns, axis=1, inplace=True)\n",
    "\n",
    "df.drop(testp2.columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric_columns = df.select_dtypes(['object']).columns\n",
    "\n",
    "df_numeric_only = df.drop(non_numeric_columns, axis=1)\n",
    "\n",
    "df = df_numeric_only\n",
    "\n",
    "df = df.drop(['match_id'], axis=1)\n",
    "\n",
    "df = df.fillna(df.median())\n",
    "\n",
    "\n",
    "def normalize(dff):\n",
    "    result = dff.copy()\n",
    "    for feature_name in dff.columns:\n",
    "        max_value = dff[feature_name].max()\n",
    "        min_value = dff[feature_name].min()\n",
    "        result[feature_name] = (\n",
    "            dff[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result\n",
    "\n",
    "\n",
    "df = normalize(df)\n",
    "# df.info()\n",
    "df = df.fillna(df.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Y = pd.DataFrame(df['y'])\n",
    "df = df.drop(['y'], axis=1)\n",
    "X = df\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=18, stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Basic parameters\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "result = model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "y_pred_proba = result.predict_proba(X_test)[::, 1]\n",
    "fpr_basic, tpr_basic, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc_basic = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr_basic, tpr_basic, label=\"Basic, auc=\" +\n",
    "         str(auc_basic), color='blue')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Hyperparameter Tuning\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': list(range(5, 25, 2)),\n",
    "    'n_estimators': list(range(80, 200, 10)),\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(model, param_grid, n_iter=10,\n",
    "                            cv=10, scoring='accuracy', n_jobs=-1, random_state=1, verbose=2)\n",
    "\n",
    "result = search.fit(X_train, y_train)\n",
    "\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cnf_matrix)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "y_pred_proba = result.predict_proba(X_test)[::, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr, tpr, label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with RFECV\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    max_depth=13, n_estimators=100, criterion='entropy')\n",
    "\n",
    "cv = StratifiedKFold(3)\n",
    "\n",
    "rfecv = RFECV(model, cv=cv, scoring='accuracy', step=1)\n",
    "\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfecv.predict(X_test)\n",
    "\n",
    "print('Optimal number of features : %d' % rfecv.n_features_)\n",
    "\n",
    "ranks = pd.DataFrame(\n",
    "    rfecv.ranking_, index=X.columns, columns=['Rank'])\n",
    "\n",
    "print(ranks.sort_values(by='Rank', ascending=True))\n",
    "\n",
    "# rfecv.support_rfecv_df = pd.DataFrame(rfecv.ranking_, index=X.columns, columns=[\n",
    "#                                       'Rank']).sort_values(by='Rank', ascending=True)\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.xlabel('Number of features selected')\n",
    "plt.ylabel('Cross validation score (nb of correct classifications)')\n",
    "plt.plot(range(1, len(rfecv.cv_results_[\n",
    "         \"mean_test_score\"]) + 1), rfecv.cv_results_[\"mean_test_score\"])\n",
    "plt.title(\"Recursive Feature Elimination \\nwith correlated features\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix\n",
    "\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cnf_matrix)\n",
    "disp.plot()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "y_pred_proba = result.predict_proba(X_test)[::, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.plot(fpr, tpr, label=\"data 1, auc=\"+str(auc), color='red')\n",
    "plt.plot(fpr_basic, tpr_basic, label=\"Basic, auc=\" +\n",
    "         str(auc_basic), color='blue')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adaBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost Basic parameters\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model = AdaBoostClassifier()\n",
    "\n",
    "result = model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "# cnf_matrix\n",
    "\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cnf_matrix)\n",
    "# disp.plot()\n",
    "# plt.show()\n",
    "\n",
    "y_pred_proba = result.predict_proba(X_test)[::, 1]\n",
    "fpr_basic, tpr_basic, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc_basic = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "# plt.plot(fpr_basic, tpr_basic, label=\"data 1, auc=\" +\n",
    "#          str(auc_basic), color='blue')\n",
    "# plt.legend(loc=4)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost Hyperparameter Tuning\n",
    "\n",
    "model = AdaBoostClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': list(range(20, 200, 10)),\n",
    "    'learning_rate': list(np.arange(0.1, 1.1, 0.1)),\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(model, param_grid, n_iter=10,\n",
    "                            cv=10, scoring='accuracy', n_jobs=-1, random_state=1, verbose=2)\n",
    "\n",
    "result = search.fit(X_train, y_train)\n",
    "\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cnf_matrix)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "y_pred_proba = result.predict_proba(X_test)[::, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr, tpr, label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost with RFECV\n",
    "\n",
    "model = AdaBoostClassifier(\n",
    "    n_estimators=190, learning_rate=0.2, random_state=17)\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(3)\n",
    "\n",
    "rfecv = RFECV(model, cv=cv, scoring='accuracy', step=1)\n",
    "\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfecv.predict(X_test)\n",
    "\n",
    "print('Optimal number of features : %d' % rfecv.n_features_)\n",
    "\n",
    "ranks = pd.DataFrame(\n",
    "    rfecv.ranking_, index=X.columns, columns=['Rank'])\n",
    "\n",
    "print(ranks.sort_values(by='Rank', ascending=True))\n",
    "\n",
    "# rfecv.support_rfecv_df = pd.DataFrame(rfecv.ranking_, index=X.columns, columns=[\n",
    "#                                       'Rank']).sort_values(by='Rank', ascending=True)\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.xlabel('Number of features selected')\n",
    "plt.ylabel('Cross validation score (nb of correct classifications)')\n",
    "plt.plot(range(1, len(rfecv.cv_results_[\n",
    "         \"mean_test_score\"]) + 1), rfecv.cv_results_[\"mean_test_score\"])\n",
    "plt.title(\"Recursive Feature Elimination \\nwith correlated features\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "# cnf_matrix\n",
    "\n",
    "\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cnf_matrix)\n",
    "# disp.plot()\n",
    "# plt.grid(False)\n",
    "# plt.show()\n",
    "\n",
    "y_pred_proba = result.predict_proba(X_test)[::, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.plot(fpr, tpr, label=\"data 1, auc=\"+str(auc), color='red')\n",
    "plt.plot(fpr_basic, tpr_basic, label=\"data 1, auc=\" +\n",
    "         str(auc_basic), color='blue')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import scikitplot as skplt\n",
    "\n",
    "model = AdaBoostClassifier(\n",
    "    n_estimators=190, learning_rate=0.2, random_state=17)\n",
    "\n",
    "\n",
    "skplt.estimators.plot_learning_curve(model, X_train, y_train, cv=10)\n",
    "\n",
    "result = model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Basic parameters\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "result = model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "y_pred_proba = result.predict_proba(X_test)[::, 1]\n",
    "fpr_basic, tpr_basic, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc_basic = metrics.roc_auc_score(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Hyperparameter Tuning\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'loss': ['log_loss', 'exponential'],\n",
    "    'learning_rate': list(np.arange(0.1, 1.1, 0.1)),\n",
    "    'n_estimators': list(range(20, 200, 10)),\n",
    "    'criterion': ['friedman_mse', 'squared_error',],\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(model, param_grid, n_iter=10,\n",
    "                            cv=10, scoring='accuracy', n_jobs=-1, random_state=1, verbose=2)\n",
    "\n",
    "result = search.fit(X_train, y_train)\n",
    "\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cnf_matrix)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "y_pred_proba = result.predict_proba(X_test)[::, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr, tpr, label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting with RFECV\n",
    "\n",
    "model = GradientBoostingClassifier(\n",
    "    loss='log_loss', learning_rate=0.1, n_estimators=100, criterion='friedman_mse')\n",
    "\n",
    "cv = StratifiedKFold(3)\n",
    "\n",
    "rfecv = RFECV(model, cv=cv, scoring='accuracy', step=1)\n",
    "\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfecv.predict(X_test)\n",
    "\n",
    "print('Optimal number of features : %d' % rfecv.n_features_)\n",
    "\n",
    "ranks = pd.DataFrame(\n",
    "    rfecv.ranking_, index=X.columns, columns=['Rank'])\n",
    "\n",
    "print(ranks.sort_values(by='Rank', ascending=True))\n",
    "\n",
    "# rfecv.support_rfecv_df = pd.DataFrame(rfecv.ranking_, index=X.columns, columns=[\n",
    "#                                       'Rank']).sort_values(by='Rank', ascending=True)\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.xlabel('Number of features selected')\n",
    "plt.ylabel('Cross validation score (nb of correct classifications)')\n",
    "plt.plot(range(1, len(rfecv.cv_results_[\n",
    "         \"mean_test_score\"]) + 1), rfecv.cv_results_[\"mean_test_score\"])\n",
    "plt.title(\"Recursive Feature Elimination \\nwith correlated features\")\n",
    "plt.show()\n",
    "\n",
    "ranks_1 = ranks[ranks['Rank'] == 1]\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix\n",
    "\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cnf_matrix)\n",
    "disp.plot()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "y_pred_proba = result.predict_proba(X_test)[::, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.plot(fpr, tpr, label=\"data 1, auc=\"+str(auc), color='red')\n",
    "plt.plot(fpr, tpr, label=\"data 1, auc=\"+str(auc_basic), color='blue')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
